"""å¬å›å¼•æ“ - è´Ÿè´£æ™ºèƒ½å¬å›ç›¸å…³å¯¹è¯"""

from __future__ import annotations

import math
from typing import List, Optional
from datetime import datetime

from kimi_cli.memory.adapters.storage.base import StorageBackend
from kimi_cli.memory.adapters.embedding.base import EmbeddingProvider
from kimi_cli.memory.models.data import RecallResult, SearchQuery


class RecallEngine:
    """å¬å›å¼•æ“
    
    èŒè´£:
    - æ„å»ºæœç´¢æŸ¥è¯¢
    - æ‰§è¡Œæ··åˆæ£€ç´¢ (å‘é‡ + å…³é”®è¯)
    - ç»“æœæ’åºå’Œè¿‡æ»¤
    - ä¸Šä¸‹æ–‡ç»„è£…
    """
    
    def __init__(
        self,
        storage: StorageBackend,
        embedding: Optional[EmbeddingProvider] = None,
    ):
        self.storage = storage
        self.embedding = embedding
    
    def recall(
        self,
        query_text: Optional[str] = None,
        query_embedding: Optional[List[float]] = None,
        current_session_id: Optional[str] = None,
        top_k: int = 5,
        min_score: float = 0.75,
    ) -> List[RecallResult]:
        """æ‰§è¡Œå¬å›
        
        Args:
            query_text: å…³é”®è¯æŸ¥è¯¢æ–‡æœ¬
            query_embedding: å‘é‡æŸ¥è¯¢
            current_session_id: å½“å‰ä¼šè¯ID (æ’é™¤)
            top_k: è¿”å›ç»“æœæ•°
            min_score: æœ€ä½ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            å¬å›ç»“æœåˆ—è¡¨
        """
        # å¦‚æœæ²¡æœ‰æä¾›embeddingä½†æœ‰textå’ŒembeddingæœåŠ¡ï¼Œè‡ªåŠ¨ç”Ÿæˆ
        if query_embedding is None and query_text and self.embedding:
            query_embedding = self.embedding.embed(query_text)
        
        # æ„å»ºæœç´¢æŸ¥è¯¢
        search_query = SearchQuery(
            text=query_text,
            embedding=query_embedding,
            session_id_to_exclude=current_session_id,
            top_k=top_k * 2,  # å¤šå–ä¸€äº›ç”¨äºè¿‡æ»¤
            min_score=min_score,
        )
        
        # æ‰§è¡Œæ··åˆæœç´¢
        results = self.storage.search_hybrid(search_query)
        
        # åº”ç”¨æ—¶é—´è¡°å‡
        results = self._apply_time_decay(results)
        
        # è¿‡æ»¤ä½åˆ†ç»“æœ
        results = [r for r in results if r.combined_score >= min_score]
        
        # é‡æ–°æ’åº
        results.sort(key=lambda x: x.combined_score, reverse=True)
        
        return results[:top_k]
    
    def recall_for_session(
        self,
        session_id: str,
        context_text: str,
        top_k: int = 5,
    ) -> List[RecallResult]:
        """ä¸ºæŒ‡å®šä¼šè¯å¬å›ç›¸å…³å†å²
        
        è¿™æ˜¯ä¸»è¦çš„ä½¿ç”¨å…¥å£ï¼ŒåŸºäºå½“å‰ä¼šè¯ä¸Šä¸‹æ–‡å¬å›ç›¸å…³å†å²
        """
        # ç”Ÿæˆembedding
        embedding = None
        if self.embedding:
            embedding = self.embedding.embed(context_text)
        
        return self.recall(
            query_text=context_text[:200],  # å–å‰200å­—ç¬¦åšå…³é”®è¯æœç´¢
            query_embedding=embedding,
            current_session_id=session_id,
            top_k=top_k,
        )
    
    def _apply_time_decay(self, results: List[RecallResult]) -> List[RecallResult]:
        """åº”ç”¨æ—¶é—´è¡°å‡å› å­"""
        now = datetime.now().timestamp()
        
        for result in results:
            days_old = (now - result.session.updated_at) / 86400
            # æŒ‡æ•°è¡°å‡
            time_factor = math.exp(-0.001 * days_old)
            
            # è°ƒæ•´ç»¼åˆåˆ†æ•°
            result.combined_score *= time_factor
            
        return results
    
    def build_prompt_context(
        self,
        results: List[RecallResult],
        max_tokens: int = 2000,
    ) -> str:
        """æ„å»ºç”¨äº prompt çš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not results:
            return ""
        
        lines = [
            "ğŸ“š [ç³»ç»Ÿæç¤º] å‘ç°ä»¥ä¸‹ç›¸å…³å†å²å¯¹è¯ï¼Œå¯èƒ½å¯¹æ‚¨æœ‰å¸®åŠ©ï¼š",
            "",
        ]
        
        current_tokens = 0
        
        for i, result in enumerate(results, 1):
            # æ ¼å¼åŒ–æ—¥æœŸ
            from datetime import datetime
            dt = datetime.fromtimestamp(result.session.updated_at)
            date_str = dt.strftime("%Y-%m-%d")
            
            # æ„å»ºæ‘˜è¦
            section_lines = [
                f"--- ç›¸å…³å¯¹è¯ #{i} ({result.session.title}) [{date_str}] ---",
                f"ç›¸ä¼¼åº¦: {result.combined_score:.2%}",
                "",
            ]
            
            # æ·»åŠ ä¸Šä¸‹æ–‡æ¶ˆæ¯
            for msg in result.context_messages:
                role_display = "ç”¨æˆ·" if msg.role == "user" else "AI"
                content = msg.content[:200] + "..." if len(msg.content) > 200 else msg.content
                section_lines.append(f"{role_display}: {content}")
            
            section_lines.append("")
            
            # ä¼°ç®—tokenæ•° (ç²—ç•¥ä¼°è®¡ï¼š1 token â‰ˆ 4 å­—ç¬¦)
            section_text = "\n".join(section_lines)
            section_tokens = len(section_text) // 4
            
            if current_tokens + section_tokens > max_tokens:
                lines.append("... (æ›´å¤šç›¸å…³å¯¹è¯å·²çœç•¥) ...")
                break
            
            lines.extend(section_lines)
            current_tokens += section_tokens
        
        lines.append("--- å†å²å¯¹è¯ç»“æŸ ---")
        lines.append("")
        
        return "\n".join(lines)
